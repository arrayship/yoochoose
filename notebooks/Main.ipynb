{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks = pd.read_csv('../data/raw/yoochoose-clicks.dat',\n",
    "        names=['sess', 'ts', 'item', 'cat'],  dtype={'cat': str},\n",
    "        usecols=['sess', 'ts', 'item'], header=None)\n",
    "clicks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt, timedelta as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks['ts'] = clicks['ts'].apply(lambda s: dt.strptime(s[:19], '%Y-%m-%dT%H:%M:%S'))\n",
    "clicks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdate = max(clicks['ts']) - td(1)\n",
    "item_count = clicks['item'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_sess = []\n",
    "remain_item = set()\n",
    "for _, group in clicks.groupby('sess', sort=False):\n",
    "    print(group.iat[0, 0], end='\\r')\n",
    "    gi = group['item'].tolist()\n",
    "    n = len(gi)\n",
    "    stop = False\n",
    "    if n > 1:\n",
    "        for item in gi:\n",
    "            if item_count[item] < 5:\n",
    "                stop = True\n",
    "                break\n",
    "    else:\n",
    "        stop = True\n",
    "    if not stop:\n",
    "        remain_sess.append((str(group.iat[0, 0]), group.iat[0, 1], gi))\n",
    "        for item in gi:\n",
    "            remain_item.add(item)\n",
    "with open('../data/interim/n_items.json', 'w') as f:\n",
    "    json.dump(len(remain_item), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "remain_item = list(remain_item)\n",
    "item_enc = LabelEncoder()\n",
    "item_enc.fit(remain_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = defaultdict(list)\n",
    "test_d = defaultdict(list)\n",
    "for sess, ts, items in remain_sess:\n",
    "    print(sess, end='\\r')\n",
    "    items = item_enc.transform(items).tolist()\n",
    "    if ts < splitdate:\n",
    "        for i in range(1, len(items)):\n",
    "            train_d[sess].append((items[: i], items[i]))\n",
    "    else:\n",
    "        for i in range(1, len(items)):\n",
    "            test_d[sess].append((items[: i], items[i]))\n",
    "with open('../data/interim/train.json', 'w') as f:\n",
    "    json.dump(train_d, f)\n",
    "with open('../data/interim/test.json', 'w') as f:\n",
    "    json.dump(test_d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YooChooseDataset(Dataset):\n",
    "    def __init__(self, d):\n",
    "        super(YooChooseDataset, self).__init__()\n",
    "        self.samples = self.add_from_dict(d)\n",
    "        \n",
    "    def add_from_dict(self, d):\n",
    "        samples = []\n",
    "        for dd in d.values():\n",
    "            for data in dd:\n",
    "                samples.append(data)\n",
    "        return samples\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_ids, y = self.samples[idx]\n",
    "        x_ids_ = set(x_ids)\n",
    "        x_ids_.remove(x_ids[- 1])\n",
    "        x_ids_ = list(x_ids_) + [x_ids[- 1]]\n",
    "        x_dict = {x_id: i for i, x_id in enumerate(x_ids_)}\n",
    "        x = [[x_id] for x_id in x_ids_]\n",
    "        edge_dict = defaultdict(lambda: defaultdict(int)) # 얘네를 다 미리 저장해야 할 듯? f-b propagation step에 비해 오래 걸리는지 확인해보고 일단\n",
    "        for i in range(len(x_ids) - 1):\n",
    "            edge_dict[x_dict[x_ids[i]]][x_dict[x_ids[i + 1]]] += 1\n",
    "        edge_index, edge_weights = [], []\n",
    "        for o in edge_dict.keys():\n",
    "            s = sum(edge_dict[o].values())\n",
    "            for d in edge_dict[o].keys():\n",
    "                edge_index.append([o, d])\n",
    "                edge_weights.append(edge_dict[o][d] / s)\n",
    "        x = torch.tensor(x, dtype=torch.long)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_weights = torch.tensor(edge_weights)\n",
    "        return Data(x, edge_index=edge_index, edge_weights=edge_weights, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# items: 37821\n",
      "# train sessions: 7957313\n",
      "# test sessions: 15270\n"
     ]
    }
   ],
   "source": [
    "with open('../data/interim/n_items.json', 'r') as f:\n",
    "    n_items = json.load(f)\n",
    "with open('../data/interim/train.json', 'r') as f:\n",
    "    train_d = json.load(f)\n",
    "with open('../data/interim/test.json', 'r') as f:\n",
    "    test_d = json.load(f)\n",
    "print('# items: {}\\n# train sessions: {}\\n# test sessions: {}'\n",
    "        .format(n_items, len(train_d), len(test_d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, val_loader, test_loader =====================split을 해서 다 만들어놔야혀,\n",
    "test_dataset = YooChooseDataset(test_d)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch_geometric.nn import GatedGraphConv\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.wq = nn.Linear(embed_dim, embed_dim)\n",
    "        self.wk = nn.Linear(embed_dim, embed_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.q = nn.Linear(embed_dim, 1)\n",
    "        self.w = nn.Linear(2 * embed_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, x, batch): # ===================================================softmax layer needed=====================================\n",
    "        sections = list(torch.bincount(batch).to('cpu').numpy())\n",
    "        x_split = torch.split(x, sections)\n",
    "        q_split = [x_[- 1].view(1, - 1) for x_ in x_split]\n",
    "        q = torch.cat([x_[- 1].view(1, - 1).repeat(x_.shape[0], 1) for x_ in x_split])\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(x)\n",
    "        a = self.q(q + k)\n",
    "        ax = a * x\n",
    "        ax_split = torch.split(ax, sections)\n",
    "        sg_split = [torch.sum(ax_, 0).view(1, - 1) for ax_ in ax_split]\n",
    "        sh_split = self.w(torch.cat((torch.cat(q_split), torch.cat(sg_split)), 1))\n",
    "        return sh_split\n",
    "    \n",
    "class PredProb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PredProb, self).__init__()\n",
    "    \n",
    "    def forward(self, sh, embedding):\n",
    "        return torch.mm(sh, embedding.weight.transpose(1, 0))\n",
    "\n",
    "class SRGNN(nn.Module):\n",
    "    def __init__(self, n_items, embed_dim):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(n_items, embed_dim)\n",
    "        self.gatedgconv = GatedGraphConv(embed_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.attention = Attention(embed_dim)\n",
    "        self.predprob = PredProb()\n",
    "        \n",
    "    def _initialize_weights(self, ):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weights, batch =\\\n",
    "                data.x, data.edge_index, data.edge_weights, data.batch\n",
    "        x = self.embedding(x).squeeze()\n",
    "        x = self.gatedgconv(x, edge_index, edge_weights)\n",
    "        x = self.relu(x)\n",
    "        x = self.attention(x, batch)\n",
    "        x = self.predprob(x, self.embedding)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2700,  0.6116,  0.0379,  ...,  0.2555,  0.6027, -0.1913],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0665,  0.0408, -0.0163,  ..., -0.0125,  0.1428,  0.0253],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([-0.6475, -0.3446,  0.0022,  ..., -0.1245, -0.4515, -0.3427],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "srgnn = SRGNN(n_items, 4)\n",
    "\n",
    "for batch in test_loader:\n",
    "    for p in srgnn(batch):\n",
    "        print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch_geometric.nn import GatedGraphConv\n",
    "\n",
    "class Embedding2Score(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Embedding2Score, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_1 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W_2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.q = nn.Linear(self.hidden_size, 1)\n",
    "        self.W_3 = nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, session_embedding, all_item_embedding, batch):\n",
    "        sections = torch.bincount(batch)\n",
    "        v_i = torch.split(session_embedding, tuple(sections.cpu().numpy()))    # split whole x back into graphs G_i\n",
    "        v_n_repeat = tuple(nodes[-1].view(1, -1).repeat(nodes.shape[0], 1) for nodes in v_i)    # repeat |V|_i times for the last node embedding\n",
    "\n",
    "        # Eq(6)\n",
    "        alpha = self.q(torch.sigmoid(self.W_1(torch.cat(v_n_repeat, dim=0)) + self.W_2(session_embedding)))    # |V|_i * 1\n",
    "        s_g_whole = alpha * session_embedding    # |V|_i * hidden_size\n",
    "        s_g_split = torch.split(s_g_whole, tuple(sections.cpu().numpy()))    # split whole s_g into graphs G_i\n",
    "        s_g = tuple(torch.sum(embeddings, dim=0).view(1, -1) for embeddings in s_g_split)\n",
    "        \n",
    "        # Eq(7)\n",
    "        v_n = tuple(nodes[-1].view(1, -1) for nodes in v_i)\n",
    "        s_h = self.W_3(torch.cat((torch.cat(v_n, dim=0), torch.cat(s_g, dim=0)), dim=1))\n",
    "        \n",
    "        # Eq(8)\n",
    "        z_i_hat = torch.mm(s_h, all_item_embedding.weight.transpose(1, 0))\n",
    "        \n",
    "        return z_i_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2807, -0.1433,  0.1594, -0.5333,  0.3918,  0.5824, -0.0843,  0.2851],\n",
       "        [-0.2402,  0.1186, -0.4569,  0.7095, -0.5262, -0.7287, -0.0643,  0.1135],\n",
       "        [-0.6767, -1.4324, -0.0564,  0.1371,  0.1189, -0.7609, -0.2928,  0.9821],\n",
       "        [ 0.4706, -0.9954,  0.1051,  0.0157,  0.2814,  0.2988,  0.2134, -0.9702],\n",
       "        [ 0.0987,  0.6412, -1.1929,  0.1105,  0.3293,  1.0259,  0.3699,  0.6783],\n",
       "        [ 0.0304,  0.3570, -0.1339,  1.2353,  0.3167,  0.3608, -0.3312, -1.0508]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeee = nn.Embedding(n_items, 8)\n",
    "gggg = GatedGraphConv(8, 1)\n",
    "ee2ss = Embedding2Score(8)\n",
    "xxxx = gggg(eeee(test_dataset[46].x).squeeze(), test_dataset[46].edge_index)\n",
    "xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5191, -1.6180, -2.1014,  ..., -0.5146,  0.8934,  0.5470]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee2ss(xxxx, eeee, batch=torch.tensor([0, 0, 0, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37123],\n",
      "        [37059],\n",
      "        [37290],\n",
      "        [37308],\n",
      "        [37116],\n",
      "        [37124]])\n",
      "tensor([[0, 5, 5, 5, 3, 4, 2, 2, 1],\n",
      "        [5, 5, 3, 2, 4, 2, 5, 1, 5]])\n",
      "tensor([1.0000, 0.5000, 0.2500, 0.2500, 1.0000, 1.0000, 0.5000, 0.5000, 1.0000])\n",
      "37290\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[46].x)\n",
    "print(test_dataset[46].edge_index)\n",
    "print(test_dataset[46].edge_weights)\n",
    "print(test_dataset[46].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2bb6946d6770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0masdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmulmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmulmul\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0masdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "asdf = torch.tensor([[1, 2, 3, 4, 5], [10, 20, 30, 40, 50], [100, 200, 300, 400, 500]], dtype=torch.float)\n",
    "mulmul = torch.tensor([1, 3, 5])\n",
    "mulmul * asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3356e+00, -2.6711e+00, -4.0067e+00, -5.3423e+00, -6.6778e+00],\n",
       "        [-1.3869e+02, -2.7739e+02, -4.1608e+02, -5.5477e+02, -6.9347e+02],\n",
       "        [-1.3921e+04, -2.7841e+04, -4.1762e+04, -5.5683e+04, -6.9603e+04]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(5, 1)(asdf) * asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "remain_item = item_enc.transform(remain_item).tolist()\n",
    "item_enc = OneHotEncoder(sparse=False)\n",
    "item_enc.fit([[item] for item in remain_item])\n",
    "with open('../data/interim/onehotencoder.pkl', 'wb') as f:\n",
    "    pickle.dump(item_enc, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('../data/raw/yoochoose-clicks.dat', 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for i, data in enumerate(reader):\n",
    "        print(data)\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buys.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BaeJR_py36",
   "language": "python",
   "name": "eagle_baejr_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
